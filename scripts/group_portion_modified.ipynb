{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Notes\n",
    "\n",
    "**Remaining to-do's:**\n",
    "* use `get_coordinates_Nominatim()` function to create a feature that indicates the distance between a property and it's host_location\n",
    "* explore dropping/cleaning observations with max nights > 365 or some large cutoff (there are ~30 instances with max nights > 2 billion)\n",
    "* Get weighted score feature (num stars weighted by num review) working -- it currently throws an overflow errror and I haven't figured out why yet\n",
    "* Target encode location cluster and all-features cluster (and also keep cluster variable) -- the sklearn `TargetEncoder()` throws and error and I haven't figured out why yet\n",
    "* Explore stacking!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1666,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, TargetEncoder, LabelEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.experimental import enable_iterative_imputer # MUST import this to enable IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.ensemble import RandomForestRegressor # For feature importance\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from scipy.stats.mstats import hmean\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = pd.to_datetime('2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>amenities</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.0</td>\n",
       "      <td>Guesthouse in Oakland · ★4.93 · 1 bedroom · 1 ...</td>\n",
       "      <td>You will be in the Crocker Highlands neighborh...</td>\n",
       "      <td>4211733</td>\n",
       "      <td>2012-11-21</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100%</td>\n",
       "      <td>89%</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Lakeshore</td>\n",
       "      <td>37.815091</td>\n",
       "      <td>-122.237531</td>\n",
       "      <td>Entire guesthouse</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>365</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>3.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>t</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>346</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>2023-11-26</td>\n",
       "      <td>4.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.86</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.0</td>\n",
       "      <td>Rental unit in San Francisco · 1 bedroom · 1 b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1257432</td>\n",
       "      <td>2011-10-06</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Our Company is San Francisco Life Real Estate,...</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>98%</td>\n",
       "      <td>81%</td>\n",
       "      <td>t</td>\n",
       "      <td>32.0</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Western Addition</td>\n",
       "      <td>37.770767</td>\n",
       "      <td>-122.427483</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Hair dryer\", \"TV\", \"Dishwasher\", \"Elevator\",...</td>\n",
       "      <td>30</td>\n",
       "      <td>365</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>30.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>t</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>317</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price                                               name  \\\n",
       "0  143.0  Guesthouse in Oakland · ★4.93 · 1 bedroom · 1 ...   \n",
       "1  103.0  Rental unit in San Francisco · 1 bedroom · 1 b...   \n",
       "\n",
       "                               neighborhood_overview  host_id  host_since  \\\n",
       "0  You will be in the Crocker Highlands neighborh...  4211733  2012-11-21   \n",
       "1                                                NaN  1257432  2011-10-06   \n",
       "\n",
       "       host_location                                         host_about  \\\n",
       "0        Oakland, CA                                                NaN   \n",
       "1  San Francisco, CA  Our Company is San Francisco Life Real Estate,...   \n",
       "\n",
       "   host_response_time host_response_rate host_acceptance_rate  \\\n",
       "0  within a few hours               100%                  89%   \n",
       "1      within an hour                98%                  81%   \n",
       "\n",
       "  host_is_superhost  host_listings_count                host_verifications  \\\n",
       "0                 f                  1.0                ['email', 'phone']   \n",
       "1                 t                 32.0  ['email', 'phone', 'work_email']   \n",
       "\n",
       "  host_has_profile_pic host_identity_verified neighbourhood_cleansed  \\\n",
       "0                    t                      t              Lakeshore   \n",
       "1                    t                      t       Western Addition   \n",
       "\n",
       "    latitude   longitude       property_type        room_type  accommodates  \\\n",
       "0  37.815091 -122.237531   Entire guesthouse  Entire home/apt             4   \n",
       "1  37.770767 -122.427483  Entire rental unit  Entire home/apt             2   \n",
       "\n",
       "  bathrooms_text  bedrooms  beds  \\\n",
       "0         1 bath       NaN   1.0   \n",
       "1         1 bath       NaN   1.0   \n",
       "\n",
       "                                           amenities  minimum_nights  \\\n",
       "0                                                 []               3   \n",
       "1  [\"Hair dryer\", \"TV\", \"Dishwasher\", \"Elevator\",...              30   \n",
       "\n",
       "   maximum_nights  minimum_minimum_nights  maximum_minimum_nights  \\\n",
       "0             365                       3                       3   \n",
       "1             365                      30                      30   \n",
       "\n",
       "   minimum_maximum_nights  maximum_maximum_nights  minimum_nights_avg_ntm  \\\n",
       "0                     365                     365                     3.0   \n",
       "1                     365                     365                    30.0   \n",
       "\n",
       "   maximum_nights_avg_ntm has_availability  availability_30  availability_60  \\\n",
       "0                   365.0                t               16               41   \n",
       "1                   365.0                t               17               40   \n",
       "\n",
       "   availability_90  availability_365  number_of_reviews  \\\n",
       "0               71               346                 14   \n",
       "1               43               317                  2   \n",
       "\n",
       "   number_of_reviews_ltm  number_of_reviews_l30d first_review last_review  \\\n",
       "0                     14                       2   2023-04-28  2023-11-26   \n",
       "1                      2                       0   2023-09-05  2023-10-31   \n",
       "\n",
       "   review_scores_rating  review_scores_accuracy  review_scores_cleanliness  \\\n",
       "0                  4.93                     5.0                       4.86   \n",
       "1                  5.00                     4.5                       4.50   \n",
       "\n",
       "   review_scores_checkin  review_scores_communication  review_scores_location  \\\n",
       "0                   4.86                          5.0                    4.93   \n",
       "1                   5.00                          5.0                    5.00   \n",
       "\n",
       "   review_scores_value instant_bookable  \n",
       "0                 4.86                f  \n",
       "1                 4.50                f  "
      ]
     },
     "execution_count": 1668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in and preview data\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df = df.drop(columns=['Id'])\n",
    "df['host_id'] = df['host_id'].astype(str)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop all instances with prices > 3000 to avoid using poor quality data\n",
    "df = df[df.price <= 3000]\n",
    "\n",
    "# nights_cols = [col for col in df.columns if 'nights' in col]\n",
    "# for col in nights_cols:\n",
    "#     df.loc[(df[col] > 2000), col] = 1125\n",
    "\n",
    "#for col in \n",
    "\n",
    "## TODO: look at dropping max nights > 365 or some large cutoff (there are ~30 instances with max nights > 2 billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into features and target\n",
    "X_orig = df.drop('price', axis=1)\n",
    "y_orig = df['price']\n",
    "\n",
    "## Drop some columns right away -- they are not used and we currently have no plan to use them\n",
    "DROP_COLS = ['name']#, 'host_location']#, 'host_about', 'host_has_profile_pic'] # TODO: look at overview again\n",
    "X_orig = X_orig.drop(DROP_COLS, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: use this function to get distance between property and host_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_Nominatim(address: str, sleep_seconds: int):\n",
    "    geocoder = Nominatim(user_agent = 'trial'+str(randint(0,1000)))\n",
    "    try:\n",
    "        result = geocoder.geocode(address)\n",
    "        sleep(randint(1 * 100, sleep_seconds * 100) / 100)\n",
    "        if result:\n",
    "            return result\n",
    "        else:\n",
    "            return None\n",
    "    except GeocoderTimedOut:\n",
    "        print('TIMED OUT: GeocoderTimedOut: Retrying...')\n",
    "        sleep(randint(1 * 100, sleep_seconds * 100) / 100)\n",
    "        return get_coordinates_Nominatim(address, sleep_seconds)\n",
    "    except GeocoderServiceError as e:\n",
    "        print('CONNECTION REFUSED: GeocoderServiceError encountered.')\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'ERROR: Terminating due to exception {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-split engineering\n",
    "\n",
    "Perform feature engineering tasks that should or can be performed on **both** train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_split_engineering(X):\n",
    "    ## Fix boolean columns\n",
    "    X['host_is_superhost'] = X['host_is_superhost'].map({'t': 1, 'f': 0})\n",
    "    X['host_identity_verified'] = X['host_identity_verified'].map({'t': 1, 'f': 0})\n",
    "    X['instant_bookable'] = X['instant_bookable'].map({'t': 1, 'f': 0})\n",
    "    X['has_availability'] = X['has_availability'].map({'t': 1, 'f': 0})\n",
    "    X['host_has_profile_pic'] = X['host_has_profile_pic'].map({'t': 1, 'f': 0})\n",
    "\n",
    "    ## Fix percentage columns\n",
    "    X['host_response_rate'] = X['host_response_rate'].str.replace('%', '').astype(float) / 100\n",
    "    X['host_acceptance_rate'] = X['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "    ## Convert dates to durations\n",
    "\n",
    "    X['host_since'] = pd.to_datetime(X['host_since'])\n",
    "    X['first_review'] = pd.to_datetime(X['first_review'])\n",
    "    \n",
    "    X['time_to_first_rev'] = (X['first_review'] - X['host_since']).dt.days\n",
    "\n",
    "    X['host_lifetime'] = (TODAY - X['host_since']).dt.days # December 2023 \n",
    "    X = X.drop('host_since', axis=1)\n",
    "\n",
    "    X['days_since_first_review'] = (TODAY - X['first_review']).dt.days # December 2023\n",
    "    X = X.drop('first_review', axis=1)\n",
    "\n",
    "    X['days_since_last_review'] = (TODAY - pd.to_datetime(X['last_review'])).dt.days # December 2023\n",
    "    X = X.drop('last_review', axis=1)\n",
    "\n",
    "    X['property_type'] = X['property_type'].fillna('other')\n",
    "    X.loc[X['property_type'].map(X['property_type'].value_counts() < 6),'property_type'] = 'other'\n",
    "\n",
    "    ## Calculate availability percentage\n",
    "    \n",
    "    X['availability_30'] = X['availability_30'] / 30\n",
    "    X['availability_60'] = X['availability_60'] / 60\n",
    "    X['availability_90'] = X['availability_90'] / 90\n",
    "    X['availability_365'] = X['availability_365'] / 365\n",
    "\n",
    "    #X = X.drop(columns=['has_availability','availability_30','availability_60','availability_90','availability_365'])\n",
    "\n",
    "    ## Add hours to host_response_time\n",
    "    X['host_response_time'] = X['host_response_time'].map({\n",
    "        'within an hour': 1,\n",
    "        'within a few hours': 6,\n",
    "        'within a day': 24,\n",
    "        'a few days or more': 48,\n",
    "    })\n",
    "\n",
    "    X['has_overview'] = X.neighborhood_overview.notnull().astype(int)\n",
    "    X = X.drop('neighborhood_overview', axis=1)\n",
    "\n",
    "    X['has_host_about'] = X.host_about.notnull().astype(int)\n",
    "    X = X.drop('host_about', axis=1)\n",
    "\n",
    "    ## Indicate if number of review is 0\n",
    "    X['has_reviews'] = X['number_of_reviews'] > 0\n",
    " \n",
    "    ### ENGINEER LOCATION ###\n",
    "\n",
    "    ## Extract number from bathrooms_text column\n",
    "    X['n_bathrooms'] = X['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "    X = X.drop('bathrooms_text', axis=1)\n",
    "\n",
    "    # ## Engineer latitude and longitude\n",
    "    X['latitude_rad'] = np.radians(X['latitude'])\n",
    "    X['longitude_rad'] = np.radians(X['longitude'])\n",
    "\n",
    "    X['coord_x'] = np.cos(X['latitude']) * np.cos(X['longitude'])\n",
    "    X['coord_y'] = np.cos(X['latitude']) * np.sin(X['longitude'])\n",
    "\n",
    "    X['host_in_CA'] = X['host_location'].str.contains(', CA', case=False, na=False).astype(int)\n",
    "    X = X.drop('host_location', axis=1)\n",
    "    # X['coord_interaction'] = X['coord_x'] * X['coord_y']\n",
    "\n",
    "    ## Calculate haversine distance to SF, Berkely, San Jose, Palo Alto, Santa Cruz\n",
    "\n",
    "    sf_lat = 37.7749\n",
    "    sf_lon = -122.4194\n",
    "    sf_target = np.radians([sf_lat, sf_lon])\n",
    "    X['dist_to_sf'] = haversine_distances(np.array([X['latitude_rad'],X['longitude_rad']]).T, sf_target.reshape(1, -1))\n",
    "\n",
    "    berk_lat = 37.8715\n",
    "    berk_lon = -122.2730\n",
    "    berk_target = np.radians([berk_lat, berk_lon])\n",
    "    X['dist_to_berkely'] = haversine_distances(np.array([X['latitude_rad'],X['longitude_rad']]).T, berk_target.reshape(1, -1))\n",
    "\n",
    "    jose_lat = 37.3387\n",
    "    jose_lon = -121.8853\n",
    "    jose_target = np.radians([jose_lat, jose_lon])\n",
    "    X['dist_to_jose'] = haversine_distances(np.array([X['latitude_rad'],X['longitude_rad']]).T, jose_target.reshape(1, -1))\n",
    "\n",
    "    palo_lat = 37.4419\n",
    "    palo_lon = -122.1430\n",
    "    palo_target = np.radians([palo_lat, palo_lon])\n",
    "    X['dist_to_sf'] = haversine_distances(np.array([X['latitude_rad'],X['longitude_rad']]).T, palo_target.reshape(1, -1))\n",
    "\n",
    "    sc_lat = 36.9741\n",
    "    sc_lon = -122.0308 \n",
    "    sc_target = np.radians([sc_lat, sc_lon])\n",
    "    X['dist_to_sc'] = haversine_distances(np.array([X['latitude_rad'],X['longitude_rad']]).T, sc_target.reshape(1, -1))\n",
    "\n",
    "    X = X.drop(columns=['latitude', 'longitude'])\n",
    "\n",
    "    ### TEXT TRANSFORMATIONS ###\n",
    "\n",
    "    ## Convert stringified lists to comma separated text for CountVectorizer\n",
    "    X['amenities'] = X['amenities'].fillna('None')\n",
    "    X['host_verifications'] = X['host_verifications'].fillna('None')\n",
    "\n",
    "    X['has_amenities'] = (X.amenities != '[]').astype(int)\n",
    "    X['n_amenities'] = X['amenities'].apply(lambda x: len(x.split(',')))\n",
    "    X = X.drop('amenities', axis=1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-split drop** drops columns that we don't want to use. We drop these before post-split engineering because some post-split engineering (interactions via `PolynomialFeatures()`, KMeans, etc.) take a long time with too many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_split_drop(X):\n",
    "    ## To drop a column from the final X dataframe, add it to this list\n",
    "    # NOTE: commented columns are KEPT\n",
    "    PRE_SPLIT_DROP = [\n",
    "        #'host_id', \n",
    "        #'host_response_time', \n",
    "        #'host_response_rate',\n",
    "        #'host_acceptance_rate', \n",
    "        #'host_is_superhost', \n",
    "        #'host_listings_count',\n",
    "        'host_verifications', \n",
    "        'host_has_profile_pic', \n",
    "        #'host_identity_verified',\n",
    "        #'neighbourhood_cleansed', # this changes results very little\n",
    "        #'property_type',  \n",
    "        #'room_type', \n",
    "        #'accommodates', \n",
    "        'bedrooms', \n",
    "        #'beds', \n",
    "        #'minimum_nights', \n",
    "        #'maximum_nights',\n",
    "        'minimum_minimum_nights',\n",
    "        'maximum_minimum_nights',\n",
    "        'minimum_maximum_nights', \n",
    "        #'maximum_maximum_nights',\n",
    "        'minimum_nights_avg_ntm', \n",
    "        'maximum_nights_avg_ntm', \n",
    "        'has_availability',\n",
    "        #'availability_30', \n",
    "        #'availability_60', \n",
    "        #'availability_90',\n",
    "        #'availability_365', \n",
    "        #'number_of_reviews', \n",
    "        #'number_of_reviews_ltm',\n",
    "        'number_of_reviews_l30d', \n",
    "        #'review_scores_rating',\n",
    "        'review_scores_accuracy', \n",
    "        'review_scores_cleanliness',\n",
    "        'review_scores_checkin', \n",
    "        'review_scores_communication',\n",
    "        'review_scores_location', \n",
    "        'review_scores_value', \n",
    "        #'instant_bookable',\n",
    "        'time_to_first_rev', \n",
    "        'host_lifetime', \n",
    "        'days_since_first_review',\n",
    "        'days_since_last_review', \n",
    "        #'has_overview', \n",
    "        #'has_host_about',\n",
    "        #'has_reviews', \n",
    "        #'n_bathrooms', \n",
    "        #'latitude_rad', \n",
    "        #'longitude_rad',\n",
    "        #'coord_x', \n",
    "        #'coord_y', \n",
    "        #'dist_to_sf', \n",
    "        #'dist_to_berkely', \n",
    "        #'dist_to_jose',\n",
    "        #'dist_to_sc',\n",
    "        #'has_amenities', \n",
    "        'n_amenities',\n",
    "        #'host_in_CA'\n",
    "        ]\n",
    "\n",
    "    X = X.drop(PRE_SPLIT_DROP, axis=1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-split feature engineering\n",
    "\n",
    "Perform feature engineering tasks that must be performed **separately** on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_split_engineering(X_train, X_test, y_train):\n",
    "    TARGET_ENCODE_COLS = ['host_id','property_type']#, 'room_type'] # TODO: get room type to work as category!\n",
    "    \n",
    "    for col in TARGET_ENCODE_COLS:\n",
    "        if col in X_train.columns:\n",
    "            enc = TargetEncoder(smooth=0)\n",
    "            X_train[col] = enc.fit_transform(np.array(X_train[col]).reshape(-1,1), y_train)\n",
    "            X_test[col] = enc.transform(np.array(X_test[col]).reshape(-1,1))\n",
    "\n",
    "    ## Normalize 5-star reviews to percentage using min-max scaling with 1 as min and 5 as max\n",
    "    RATING_COLS = [col for col in X_train.columns if 'review_scores' in col]\n",
    "\n",
    "    ## Combine and normalize review scores\n",
    "    X_train['review_scores'] = X_train[RATING_COLS].mean(axis=1)\n",
    "    X_test['review_scores'] = X_test[RATING_COLS].mean(axis=1)\n",
    "    X_train['review_scores'] = (X_train['review_scores'] - 1) / (5 - 1)\n",
    "    X_test['review_scores'] = (X_test['review_scores'] - 1) / (5 - 1)\n",
    "    X_train['review_scores_rank'] = X_train['review_scores'].rank(pct=True)\n",
    "    X_test['review_scores_rank'] = X_test['review_scores'].rank(pct=True)\n",
    "\n",
    "    ## TODO: fix overflow errror from weighted score\n",
    "    # X_train['weighted_score'] = X_train['review_scores'] * 10 * np.log(X_train['number_of_reviews'])\n",
    "    # X_train['weighted_score_rank'] = X_train['weighted_score'].rank(pct=True)\n",
    "    # X_test['weighted_score'] = X_test['review_scores'] * 10 * np.log(X_test['number_of_reviews'])\n",
    "    # X_test['weighted_score_rank'] = X_test['weighted_score'].rank(pct=True)\n",
    "\n",
    "    # X_train = X_train.drop(columns=['host_id'])\n",
    "    # X_test = X_test.drop(columns=['host_id'])\n",
    "\n",
    "    ## Cluster by location only\n",
    "    latlon_clustering = KMeans(n_clusters=2, random_state=9) # Joe Burrow # 4 FOUR!!!\n",
    "    train_latlon_cluster_labels = latlon_clustering.fit_predict(X_train[['coord_x', 'coord_y']])\n",
    "    test_latlon_cluster_labels = latlon_clustering.fit_predict(X_test[['coord_x', 'coord_y']])\n",
    "\n",
    "    X_train['location_cluster'] = train_latlon_cluster_labels\n",
    "    X_test['location_cluster'] = test_latlon_cluster_labels\n",
    "\n",
    "    ## Change cluster to int\n",
    "    X_train['location_cluster'] = X_train['location_cluster'].astype(int)\n",
    "    X_test['location_cluster'] = X_test['location_cluster'].astype(int)\n",
    "\n",
    "    ## Target encode location clusters TODO: fix target encoding here\n",
    "    # enc = TargetEncoder()\n",
    "    # X_train['location_cluster_y'] = enc.fit_transform(np.array(X_train['location_cluster']).reshape(-1,1), y_train)\n",
    "    # X_test['location_cluster_y'] = enc.transform(np.array(X_test['location_cluster']).reshape(-1,1))\n",
    "\n",
    "    ## Define pipeline for numeric features\n",
    "    numeric_pipe = Pipeline([ # NOTE: assumes preprocessor has already been run\n",
    "        ('impute', IterativeImputer(random_state=9)), # Joe Burrow\n",
    "        #('poly',PolynomialFeatures(interaction_only=True, include_bias=False)),#degree=2, include_bias=False)),\n",
    "        #('standardize',StandardScaler(with_mean=True, with_std=True))\n",
    "    ])\n",
    "\n",
    "    ## Create col transformer for numeric features\n",
    "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_features = X_train.select_dtypes(exclude=['int64','float64']).columns\n",
    "\n",
    "    numeric_transformer = ColumnTransformer([\n",
    "        ('num', numeric_pipe, numeric_features)\n",
    "    ])\n",
    "\n",
    "    cols = X_train.columns\n",
    "\n",
    "    X_train = numeric_transformer.fit_transform(X_train, y_train)\n",
    "    X_test = numeric_transformer.transform(X_test)\n",
    " \n",
    "    #X_train.loc[:,numeric_features] = numeric_transformer.fit_transform(X_train, y_train)\n",
    "    #X_test.loc[:,numeric_features] = numeric_transformer.transform(X_test)\n",
    "\n",
    "    ## Combine transformed numeric and categorical features\n",
    "    #X_train = pd.concat([X_train_numeric.reset_index(), X_train[cat_features]], axis=1)\n",
    "    #X_test = pd.concat([X_test_numeric.reset_index(), X_test[cat_features]], axis=1)\n",
    "\n",
    "    #X_train = pd.conat([X_train[cat_features].reset_index(drop=True), X_train_numeric.reset_index(drop=True)], axis=1) #numeric_pipe.fit_transform(X_train, y_train)\n",
    "    #X_test = pd.concat([X_test[cat_features].reset_index(drop=True), X_test_numeric.reset_index(drop=True)], axis=1) #numeric_pipe.transform(X_test)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns=numeric_features)\n",
    "    X_test = pd.DataFrame(X_test, columns=numeric_features)\n",
    "\n",
    "    #X_train.loc[:,cat_features] = X_train[cat_features].astype('category')\n",
    "    #X_test.loc[:,cat_features] = X_test[cat_features].astype('category')\n",
    "\n",
    "    ## Extract linear model coefficients and feature names\n",
    "    # X_names = numeric_transformer.named_steps_['num'].named_steps['poly'].get_feature_names_out() # X0, X1, X2, X2^2, X1*X2, etc.\n",
    "    # x_mapping = {f'x{i}':name for i,name in enumerate(cols)} # X0=Salnty, etc.\n",
    "\n",
    "    # ## Turn x names into actual feature names with x_mapping\n",
    "    # actual_names = X_names.copy()\n",
    "    # for x in X_names:\n",
    "    #     for key in x_mapping:\n",
    "    #         if key in x:\n",
    "    #             actual_names = [re.sub(key,x_mapping[key],x) for x in actual_names]\n",
    "\n",
    "    ## Cluster by everything\n",
    "    clustering = KMeans(n_clusters=3, random_state=9) # Joe Burrow\n",
    "    train_cluster_labels = clustering.fit_predict(X_train)#[numeric_features])\n",
    "    test_cluster_labels = clustering.fit_predict(X_test)#[numeric_features])\n",
    "\n",
    "    ## Add column to X_train and X_test\n",
    "    X_train['cluster'] = train_cluster_labels\n",
    "    X_test['cluster'] = test_cluster_labels\n",
    "\n",
    "    ## Target encode cluster TODO: fix target encoding here\n",
    "    # enc2 = TargetEncoder()\n",
    "    # X_train['cluster_y'] = enc2.fit_transform(np.array(X_train['cluster']).reshape(-1,1), y_train)\n",
    "    # X_test['cluster_y'] = enc2.transform(np.array(X_test['cluster']).reshape(-1,1))\n",
    "    \n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline for testing/iteration\n",
    "\n",
    "Perform train/test split on known data to evaluate feature engineering, perform variable selection, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_engineered = pre_split_engineering(X_orig) # Perform pre-split engineering\n",
    "X_engineered_cleaned = pre_split_drop(X_engineered) # Drop columns that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Perform train-test split and post-split engineering\n",
    "X_train_, X_test_, y_train_, y_test = train_test_split(X_engineered_cleaned, y_orig, test_size=0.2, random_state=9) # Joe Burrow\n",
    "X_train, X_test, y_train = post_split_engineering(X_train_, X_test_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1677,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change object columns to category\n",
    "cat_cols = X_train.select_dtypes(include='object').columns\n",
    "X_train[cat_cols] = X_train[cat_cols].astype('category')\n",
    "X_test[cat_cols] = X_test[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_index = X_test.index\n",
    "\n",
    "# ## Train a model for each cluster\n",
    "# models = {f'cluster_{i}': LGBMRegressor(num_iterations=600, learning_rate=0.1, objective='huber', random_state=9) for i in range(len(pd.Series(train_latlon_cluster_labels).unique()))}\n",
    "# preds = {f'cluster_{i}': None for i in range(len(pd.Series(train_latlon_cluster_labels).unique()))}\n",
    "\n",
    "# for cluster in pd.Series(train_latlon_cluster_labels).unique():\n",
    "#     print(f'Training model for cluster {cluster}...')\n",
    "\n",
    "#     X_train_filtered = X_train.loc[train_latlon_cluster_labels == cluster, X_train.select_dtypes(include=['int64','float64']).columns]\n",
    "#     y_train_filtered = y_train[train_latlon_cluster_labels == cluster]\n",
    "\n",
    "#     X_test_filtered = X_test.loc[test_latlon_cluster_labels == cluster, X_train.select_dtypes(include=['int64','float64']).columns]\n",
    "#     y_test_filtered = y_test[test_latlon_cluster_labels == cluster]\n",
    "\n",
    "#     ## Drop location cluster\n",
    "#     X_train_filtered = X_train_filtered.drop('location_cluster', axis=1)\n",
    "#     X_test_filtered = X_test_filtered.drop('location_cluster', axis=1)\n",
    "\n",
    "#     models[f'cluster_{cluster}'].fit(X_train_filtered, np.log(y_train_filtered))\n",
    "#     print(f'Model for cluster {cluster} trained.')\n",
    "\n",
    "#     ## Predict on test set\n",
    "#     preds[f'cluster_{cluster}'] = pd.Series(np.exp(models[f'cluster_{cluster}'].predict(X_test_filtered)), index=X_test_filtered.index)\n",
    "\n",
    "# ## Concat predictions and sort by index\n",
    "# all_y = pd.concat([preds[f'cluster_{cluster}'] for cluster in range(len(preds)) if cluster in pd.Series(train_latlon_cluster_labels).unique()])#.sort_index(compare_index)\n",
    "\n",
    "# ## Sort all y by order of compare_index\n",
    "# y_pred_testing = all_y.reindex(compare_index)\n",
    "\n",
    "# mean_absolute_error(y_test, y_pred_testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop cluster 2\n",
    "keep_index = (X_train['cluster'] != 1).to_numpy()\n",
    "X_train = X_train.loc[keep_index,:]\n",
    "y_train = y_train[keep_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_partition(X_train, X_test, y_train, col, cutoff, score=False):\n",
    "    compare_index = X_test.index\n",
    "    is_small_company_train = (X_train[col] > cutoff).to_numpy()\n",
    "    is_small_company_test = (X_test[col] > cutoff).to_numpy()\n",
    "\n",
    "    small_company_model = LGBMRegressor(num_iterations=600, learning_rate=0.1, objective='huber', random_state=9)\n",
    "    large_company_model = LGBMRegressor(num_iterations=600, learning_rate=0.1, objective='huber', random_state=9)   \n",
    "\n",
    "    small_company_model.fit(X_train[is_small_company_train], np.log(y_train[is_small_company_train]))\n",
    "    large_company_model.fit(X_train[~is_small_company_train], np.log(y_train[~is_small_company_train]))\n",
    "\n",
    "    small_y_pred = pd.Series(np.exp(small_company_model.predict(X_test[is_small_company_test])), index=X_test[is_small_company_test].index)\n",
    "    large_y_pred = pd.Series(np.exp(large_company_model.predict(X_test[~is_small_company_test])), index=X_test[~is_small_company_test].index)\n",
    "\n",
    "    y_pred_testing = pd.concat([small_y_pred, large_y_pred]).reindex(compare_index)\n",
    "    \n",
    "    if score:\n",
    "        print(f'MAE: {mean_absolute_error(y_test, y_pred_testing)}')\n",
    "\n",
    "    return y_pred_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3278\n",
      "[LightGBM] [Info] Number of data points in the train set: 1049, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 5.305337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4882\n",
      "[LightGBM] [Info] Number of data points in the train set: 11062, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 4.955617\n",
      "MAE: 55.60505493115693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       123.539980\n",
       "1        67.821683\n",
       "2        92.214198\n",
       "3       156.782852\n",
       "4        90.396725\n",
       "           ...    \n",
       "3030     71.520873\n",
       "3031    213.496844\n",
       "3032    105.753710\n",
       "3033    105.871984\n",
       "3034    202.886971\n",
       "Length: 3035, dtype: float64"
      ]
     },
     "execution_count": 1681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_predict_partition(X_train, X_test, 'latitude_rad', np.radians(37.8253), score=True)\n",
    "train_predict_partition(X_train, X_test, y_train, col='host_listings_count', cutoff=200, score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4933\n",
      "[LightGBM] [Info] Number of data points in the train set: 12111, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 4.985908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-85 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-85 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-85 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-85 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-85 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-85 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-85 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-85 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-85 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-85 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-85 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-85 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-85 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-85 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-85 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-85 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-85 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-85 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-85 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-85\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(num_iterations=625, objective=&#x27;huber&#x27;, random_state=9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" checked><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(num_iterations=625, objective=&#x27;huber&#x27;, random_state=9)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(num_iterations=625, objective='huber', random_state=9)"
      ]
     },
     "execution_count": 1682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_model = LGBMRegressor(num_iterations=625, learning_rate=0.1, objective='huber', random_state=9)#, categorical_feature=f'name:{X_train.select_dtypes(\"category\").columns}') # Joe Burrow\n",
    "testing_model.fit(X_train[X_train.select_dtypes(exclude=['category']).columns], np.log(y_train)) #[X_train.select_dtypes(include=['int64','float64']).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.96112439383056"
      ]
     },
     "execution_count": 1683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_testing = np.exp(testing_model.predict(X_test[X_train.select_dtypes(exclude=['category']).columns]))\n",
    "mean_absolute_error(y_test, y_pred_testing) \n",
    "# for reference, the score of ~100 on Kaggle got ~63.46 here. The score of 91.5 on Kaggle got a 57.16 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline to predict for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in and preview data\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "newdata = pd.read_csv('../data/test.csv')\n",
    "\n",
    "data = data.drop(columns=['Id'])\n",
    "new_data_id = newdata['Id']\n",
    "newdata = newdata.drop(columns=['Id'])\n",
    "\n",
    "data['host_id'] = data['host_id'].astype(str)\n",
    "newdata['host_id'] = newdata['host_id'].astype(str)\n",
    "\n",
    "data = data.drop(DROP_COLS, axis=1)\n",
    "newdata = newdata.drop(DROP_COLS, axis=1)\n",
    "\n",
    "## Split data into features and target\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = pre_split_engineering(X) # All data with known y\n",
    "newdata_1 = pre_split_engineering(newdata) # New data for Kaggle\n",
    "\n",
    "X_2  = pre_split_drop(X_1) # All data with known y\n",
    "newdata_2 = pre_split_drop(newdata_1) # New data for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, newdata_final, y = post_split_engineering(X_train=X_2, X_test=newdata_2, y_train=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If predicting off partition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3319\n",
      "[LightGBM] [Info] Number of data points in the train set: 1341, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 5.368042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4938\n",
      "[LightGBM] [Info] Number of data points in the train set: 13933, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 4.984020\n"
     ]
    }
   ],
   "source": [
    "y_pred = train_predict_partition(X_train=X, X_test=newdata_final, y_train=y, col='host_listings_count', cutoff=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If **tuning hyperparams** from scratch... Otherwise, use predetermined hyperparams. Tune time is ~22 mins on 4 threads.\n",
    "\n",
    "LightGBM hyperparameters outlined at https://lightgbm.readthedocs.io/en/latest/Parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model to tune; set `num_threads` or `device` to train faster\n",
    "tuned_model = LGBMRegressor(num_threads=4, objective='huber', random_state=9) # Joe Burrow # device='gpu'\n",
    "\n",
    "## Tune hyperparameters with random search\n",
    "# param_distributions = {\n",
    "#     'num_iterations': [300,400,500], #range(75, 501, 25),\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     #'max_depth': [2,3,4,5,6],    #'num_leaves': range(20, 61, 5),\n",
    "#     #'n_neighbors': range(1,101),\n",
    "#     #'weights': ['uniform', 'distance'],\n",
    "# }\n",
    "\n",
    "fine_tune_grid = {\n",
    "    'num_iterations': [500,550,600], #range(75, 501, 25),\n",
    "    'learning_rate': [0.75, 0.1, 0.125],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(tuned_model, fine_tune_grid,  verbose=False,\n",
    "                            n_iter=100, cv=30,  # 30-fold cross-validation seems to be a good balance between time and accuracy\n",
    "                            scoring='neg_mean_absolute_error', random_state=9) # Joe Burrow\n",
    "\n",
    "search.fit(X, np.log(y))\n",
    "print(search.best_params_)\n",
    "\n",
    "y_pred = np.exp(search.predict(newdata_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If predicting with **known/predetermined hyperparams**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scottbrown/byu/stat486/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 15274, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 5.017736\n",
      "Model fit. Predicting...\n"
     ]
    }
   ],
   "source": [
    "## Create model with best hyperparams (last tuned on 2/20 around 4:45 PM)\n",
    "tuned_model = LGBMRegressor(num_iterations=625, learning_rate=0.1, random_state=9, objective='huber') # Joe Burrow\n",
    "tuned_model.fit(X, np.log(y))\n",
    "print('Model fit. Predicting...')\n",
    "y_pred = np.exp(tuned_model.predict(newdata_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out predictions for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PSJEN</td>\n",
       "      <td>70.638006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PVZW7</td>\n",
       "      <td>164.253129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EJLAM</td>\n",
       "      <td>50.724875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDHPB</td>\n",
       "      <td>58.129009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MJGYX</td>\n",
       "      <td>289.844416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id       price\n",
       "0  PSJEN   70.638006\n",
       "1  PVZW7  164.253129\n",
       "2  EJLAM   50.724875\n",
       "3  SDHPB   58.129009\n",
       "4  MJGYX  289.844416"
      ]
     },
     "execution_count": 1691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Output predictions to csv\n",
    "output = pd.DataFrame({'Id': new_data_id, 'price': y_pred})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('../data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat486",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
